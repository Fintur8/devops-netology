# 1) На лекции мы познакомились с node_exporter. В демонстрации его исполняемый файл запускался в background. Этого достаточно для демо, но не для настоящей production-системы, где процессы должны находиться под внешним управлением. 

Используя знания из лекции по systemd, создайте самостоятельно простой unit-файл для node_exporter:  
поместите его в автозагрузку,  
предусмотрите возможность добавления опций к запускаемому процессу через внешний файл (посмотрите, например, на systemctl cat cron),  
удостоверьтесь, что с помощью systemctl процесс корректно стартует, завершается, а после перезагрузки автоматически поднимается.  

Выполнил установку  node_exporter.  

wget https://github.com/prometheus/node_exporter/releases/download/v1.2.2/node_exporter-1.2.2.linux-amd64.tar.gz    
tar xvfz node_exporter-1.2.2.linux-amd64.tar.gz    
cd node_exporter-1.2.2.linux-amd64.tar.gz    

Прописал порты в vagrantfile:  
config.vm.network "forwarded_port", guest: 9100, host: 9100  
Проверил работу node_exporter:  
./node_exporter:  
http://localhost:9100/metrics  

HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles.  
TYPE go_gc_duration_seconds summary  
go_gc_duration_seconds{quantile="0"} 0  
go_gc_duration_seconds{quantile="0.25"} 0  
go_gc_duration_seconds{quantile="0.5"} 0  
go_gc_duration_seconds{quantile="0.75"} 0  
go_gc_duration_seconds{quantile="1"} 0  
go_gc_duration_seconds_sum 0  
go_gc_duration_seconds_count 0  
HELP go_goroutines Number of goroutines that currently exist.  
TYPE go_goroutines gauge  
go_goroutines 8  
HELP go_info Information about the Go environment.  
TYPE go_info gauge  
go_info{version="go1.16.7"} 1  
HELP go_memstats_alloc_bytes Number of bytes allocated and still in use.  
TYPE go_memstats_alloc_bytes gauge  
go_memstats_alloc_bytes 1.33332e+06  
HELP go_memstats_alloc_bytes_total Total number of bytes allocated, even if freed.  
TYPE go_memstats_alloc_bytes_total counter  
go_memstats_alloc_bytes_total 1.33332e+06  
HELP go_memstats_buck_hash_sys_bytes Number of bytes used by the profiling bucket hash table.  
TYPE go_memstats_buck_hash_sys_bytes gauge  
go_memstats_buck_hash_sys_bytes 1.445394e+06  
HELP go_memstats_frees_total Total number of frees.  
TYPE go_memstats_frees_total counter  
go_memstats_frees_total 739  
HELP go_memstats_gc_cpu_fraction The fraction of this program's available CPU time used by the GC since the program started.  
TYPE go_memstats_gc_cpu_fraction gauge  
go_memstats_gc_cpu_fraction 0  
HELP go_memstats_gc_sys_bytes Number of bytes used for garbage collection system metadata.  
TYPE go_memstats_gc_sys_bytes gauge  
go_memstats_gc_sys_bytes 4.178024e+06  
HELP go_memstats_heap_alloc_bytes Number of heap bytes allocated and still in use.  
TYPE go_memstats_heap_alloc_bytes gauge  
go_memstats_heap_alloc_bytes 1.33332e+06  
HELP go_memstats_heap_idle_bytes Number of heap bytes waiting to be used.  
TYPE go_memstats_heap_idle_bytes gauge  
go_memstats_heap_idle_bytes 6.4438272e+07  
HELP go_memstats_heap_inuse_bytes Number of heap bytes that are in use.  
TYPE go_memstats_heap_inuse_bytes gauge  
go_memstats_heap_inuse_bytes 2.37568e+06  
HELP go_memstats_heap_objects Number of allocated objects.  
TYPE go_memstats_heap_objects gauge  
go_memstats_heap_objects 8948  
HELP go_memstats_heap_released_bytes Number of heap bytes released to OS.  
TYPE go_memstats_heap_released_bytes gauge  
go_memstats_heap_released_bytes 6.4438272e+07  
HELP go_memstats_heap_sys_bytes Number of heap bytes obtained from system.  
TYPE go_memstats_heap_sys_bytes gauge  
go_memstats_heap_sys_bytes 6.6813952e+07  

# Создал простой unit-файл для node_exporter:

vagrant@vagrant:~$ cat /etc/systemd/system/node_exporter.service  
[Unit]  
Description=Node Exporter  
After=network.target  

[Service]  
User=node_exporter  
Group=node_exporter  
Type=simple  
ExecStart=/usr/local/bin/node_exporter  
EnvironmentFile=-/etc/default/node_exporte  
Restart=on-failure  
RestartSec=10s  

[Install]  
WantedBy=multi-user.target  

# предусмотрите возможность добавления опций к запускаемому процессу через внешний файл (посмотрите, например, на systemctl cat cron)  
# Посмотрел в крон и у меня 2 варианта :  
EnvironmentFile=-/etc/default/node_exporter  Определяет путь для внешнего файла с опциями   
ExecStart=/usr/local/bin/node_exporter ${OPTS_ONE} - при наличии внешнего файла с опциями, вместо ${OPTS_ONE} подставит точное значение OPTS_ONE в EnvironmentFile.    

# Удостоверьтесь, что с помощью systemctl процесс корректно стартует, завершается, а после перезагрузки автоматически поднимается.

# Сервис стартует: 

# sudo systemctl status node_exporter.service
● node_exporter.service - Node Exporter  
     Loaded: loaded (/etc/systemd/system/node_exporter.service; enabled; vendor preset: enabled)  
     Active: active (running) since Fri 2021-11-05 13:21:53 UTC; 28min ago  
   Main PID: 638 (node_exporter)  
      Tasks: 4 (limit: 1112)  
     Memory: 17.7M  
     CGroup: /system.slice/node_exporter.service  
             └─638 /usr/local/bin/node_exporter  

Nov 05 13:21:53 vagrant node_exporter[638]: level=info ts=2021-11-05T13:21:53.220Z caller=node_exporter.go:115 collector=thermal_zone  
Nov 05 13:21:53 vagrant node_exporter[638]: level=info ts=2021-11-05T13:21:53.220Z caller=node_exporter.go:115 collector=time  
Nov 05 13:21:53 vagrant node_exporter[638]: level=info ts=2021-11-05T13:21:53.220Z caller=node_exporter.go:115 collector=timex  
Nov 05 13:21:53 vagrant node_exporter[638]: level=info ts=2021-11-05T13:21:53.220Z caller=node_exporter.go:115 collector=udp_queues  
Nov 05 13:21:53 vagrant node_exporter[638]: level=info ts=2021-11-05T13:21:53.220Z caller=node_exporter.go:115 collector=uname  
Nov 05 13:21:53 vagrant node_exporter[638]: level=info ts=2021-11-05T13:21:53.220Z caller=node_exporter.go:115 collector=vmstat  
Nov 05 13:21:53 vagrant node_exporter[638]: level=info ts=2021-11-05T13:21:53.220Z caller=node_exporter.go:115 collector=xfs  
Nov 05 13:21:53 vagrant node_exporter[638]: level=info ts=2021-11-05T13:21:53.220Z caller=node_exporter.go:115 collector=zfs  
Nov 05 13:21:53 vagrant node_exporter[638]: level=info ts=2021-11-05T13:21:53.222Z caller=node_exporter.go:199 msg="Listening on" address=:9100  
Nov 05 13:21:53 vagrant node_exporter[638]: level=info ts=2021-11-05T13:21:53.233Z caller=tls_config.go:191 msg="TLS is disabled." http2=false  

# Остановка
  vagrant@vagrant:$ sudo systemctl stop node_exporter.service  
  vagrant@vagrant:$ sudo systemctl status node_exporter.service  
● node_exporter.service - Node Exporter  
     Loaded: loaded (/etc/systemd/system/node_exporter.service; enabled; vendor preset: enabled)  
     Active: inactive (dead) since Fri 2021-11-05 14:05:55 UTC; 56s ago  
    Process: 638 ExecStart=/usr/local/bin/node_exporter (code=killed, signal=TERM)  
   Main PID: 638 (code=killed, signal=TERM)  

Nov 05 13:21:53 vagrant node_exporter[638]: level=info ts=2021-11-05T13:21:53.220Z caller=node_exporter.go:115 collector=udp_queues  
Nov 05 13:21:53 vagrant node_exporter[638]: level=info ts=2021-11-05T13:21:53.220Z caller=node_exporter.go:115 collector=uname  
Nov 05 13:21:53 vagrant node_exporter[638]: level=info ts=2021-11-05T13:21:53.220Z caller=node_exporter.go:115 collector=vmstat  
Nov 05 13:21:53 vagrant node_exporter[638]: level=info ts=2021-11-05T13:21:53.220Z caller=node_exporter.go:115 collector=xfs  
Nov 05 13:21:53 vagrant node_exporter[638]: level=info ts=2021-11-05T13:21:53.220Z caller=node_exporter.go:115 collector=zfs  
Nov 05 13:21:53 vagrant node_exporter[638]: level=info ts=2021-11-05T13:21:53.222Z caller=node_exporter.go:199 msg="Listening on" address=:9100  
Nov 05 13:21:53 vagrant node_exporter[638]: level=info ts=2021-11-05T13:21:53.233Z caller=tls_config.go:191 msg="TLS is disabled." http2=false  
Nov 05 14:05:55 vagrant systemd[1]: Stopping Node Exporter...  
Nov 05 14:05:55 vagrant systemd[1]: node_exporter.service: Succeeded.  
Nov 05 14:05:55 vagrant systemd[1]: Stopped Node Exporter.  

# Перезапускается корректно 
  vagrant@vagrant:$ sudo systemctl restart node_exporter.service  
  vagrant@vagrant:$ sudo systemctl status node_exporter.service  
● node_exporter.service - Node Exporter  
     Loaded: loaded (/etc/systemd/system/node_exporter.service; enabled; vendor preset: enabled)  
     Active: active (running) since Fri 2021-11-05 14:07:56 UTC; 1s ago  
   Main PID: 1049 (node_exporter)  
      Tasks: 4 (limit: 1112)  
     Memory: 2.2M  
     CGroup: /system.slice/node_exporter.service  
             └─1049 /usr/local/bin/node_exporter  

Nov 05 14:07:56 vagrant node_exporter[1049]: level=info ts=2021-11-05T14:07:56.966Z caller=node_exporter.go:115 collector=thermal_zone  
Nov 05 14:07:56 vagrant node_exporter[1049]: level=info ts=2021-11-05T14:07:56.966Z caller=node_exporter.go:115 collector=time  
Nov 05 14:07:56 vagrant node_exporter[1049]: level=info ts=2021-11-05T14:07:56.966Z caller=node_exporter.go:115 collector=timex  
Nov 05 14:07:56 vagrant node_exporter[1049]: level=info ts=2021-11-05T14:07:56.966Z caller=node_exporter.go:115 collector=udp_queues  
Nov 05 14:07:56 vagrant node_exporter[1049]: level=info ts=2021-11-05T14:07:56.966Z caller=node_exporter.go:115 collector=uname  
Nov 05 14:07:56 vagrant node_exporter[1049]: level=info ts=2021-11-05T14:07:56.966Z caller=node_exporter.go:115 collector=vmstat  
Nov 05 14:07:56 vagrant node_exporter[1049]: level=info ts=2021-11-05T14:07:56.966Z caller=node_exporter.go:115 collector=xfs  
Nov 05 14:07:56 vagrant node_exporter[1049]: level=info ts=2021-11-05T14:07:56.966Z caller=node_exporter.go:115 collector=zfs  
Nov 05 14:07:56 vagrant node_exporter[1049]: level=info ts=2021-11-05T14:07:56.967Z caller=node_exporter.go:199 msg="Listening on" address=:9100  
Nov 05 14:07:56 vagrant node_exporter[1049]: level=info ts=2021-11-05T14:07:56.967Z caller=tls_config.go:191 msg="TLS is disabled." http2=false  


# 2)Ознакомьтесь с опциями node_exporter и выводом /metrics по-умолчанию. Приведите несколько опций, которые вы бы выбрали для базового мониторинга хоста по CPU, памяти, диску и сети.
# CPU:
node_cpu_seconds_total{cpu="0",mode="idle"}  
node_cpu_seconds_total{cpu="0",mode="system"}  
node_cpu_seconds_total{cpu="0",mode="user"}  
node_cpu_seconds_total{cpu="1",mode="idle"}  
node_cpu_seconds_total{cpu="1",mode="system"}  
node_cpu_seconds_total{cpu="1",mode="user"}  
process_cpu_seconds_total  

# Память:
node_memory_MemTotal_bytes.  
node_memory_MemFree_bytes.  
node_memory_Cached_bytes.  
node_memory_Buffers_bytes.  

# Диск:
node_disk_io_now  
node_disk_io_time_seconds_total  
node_disk_read_bytes_total  
node_disk_read_time_seconds_total  
node_disk_write_time_seconds_total  

# Сеть:
node_network_up  
node_network_receive_bytes_total  
node_network_receive_drop_total  
node_network_receive_errs_total  
node_network_speed_bytes  
node_network_transmit_bytes_total  
node_network_transmit_packets_total  
node_network_transmit_errs_total  
node_network_transmit_drop_total  

# 3) Установите в свою виртуальную машину Netdata.

Установил Netdata  sudo apt install -y netdata  
В конфигурационном файле /etc/netdata/netdata.conf в секции [web] (у меня секция [global])  заменил значение с 127.0.0.1 на  bind socket to IP = 0.0.0.0  
Добавил в  Vagrantfile config.vm.network "forwarded_port", guest: 19999, host: 19999  

vagrant@vagrant:~$ sudo lsof -i :19999  
COMMAND PID    USER   FD   TYPE DEVICE SIZE/OFF NODE NAME  
netdata 738 netdata    4u  IPv4  23157      0t0  TCP *:19999 (LISTEN)  
netdata 738 netdata   33u  IPv4  28281      0t0  TCP vagrant:19999->_gateway:61158 (ESTABLISHED)  

Total CPU utilization (all cores). 100% here means there is no CPU idle time at all. You can get per core usage at the CPUs section and per application usage at the Applications Monitoring section.  
Keep an eye on iowait  
(0%). If it is constantly high, your disks are a bottleneck and they slow your system down.  
An important metric worth monitoring, is softirq  
(0,00%). A constantly high percentage of softirq may indicate network driver issues.  


# 4) Можно ли по выводу dmesg понять, осознает ли ОС, что загружена не на настоящем оборудовании, а на системе виртуализации?

Да, судя по выводу  

DMI: innotek GmbH VirtualBox/VirtualBox, BIOS VirtualBox 12/01/2006  
Hypervisor detected: KVM  
CPU MTRRs all blank - virtualized system.  
Booting paravirtualized kernel on KVM  

# 5) Как настроен sysctl fs.nr_open на системе по-умолчанию? Узнайте, что означает этот параметр. Какой другой существующий лимит не позволит достичь такого числа (ulimit --help)?

vagrant@vagrant:$ sysctl fs.nr_open  
fs.nr_open = 1048576  
Это означает максимальное количество дескрипторов файлов, которое может выделить процесс. Значение по умолчанию - 1048576  

vagrant@vagrant:$ ulimit -Sn  
1024  
vagrant@vagrant:$ ulimit -Hn  
1048576  

ulimit -Sn  мягкий лимит   

vagrant@vagrant:~$ ulimit -Hn  
1048576  

 ulimit -Hn жесткий   

Оба лимит не могут превысить системный fs.nr_open  

# 6) Запустите любой долгоживущий процесс (не ls, который отработает мгновенно, а, например, sleep 1h) в отдельном неймспейсе процессов; покажите, что ваш процесс работает под PID 1 через nsenter. 

root@vagrant:# ps -e | grep sleep  
   1356 pts/2    00:00:00 sleep  
root@vagrant:# nsenter --target 1356 --pid --mount  
root@vagrant:/# ps  
    PID TTY          TIME CMD  
      2 pts/0    00:00:00 bash  
     11 pts/0    00:00:00 ps  

# 7)Найдите информацию о том, что такое :(){ :|:& };:. Запустите эту команду в своей виртуальной машине Vagrant с Ubuntu 20.04 (это важно, поведение в других ОС не проверялось). Некоторое время все будет "плохо", после чего (минуты) – ОС должна стабилизироваться. Вызов dmesg расскажет, какой механизм помог автоматической стабилизации. Как настроен этот механизм по-умолчанию, и как изменить число процессов, которое можно создать в сессии?

:(){ :|:& };: - Логическая бомба (известная также как fork bomb), забивающая память системы, что в итоге приводит к её зависанию.  

cgroup: fork rejected by pids controller in /user.slice/user-1000.slice/session-1.scope  
механизм — cgroups помог автоматической стабилизации.  

Существует формула для расчета максимального количества активных PID или потоков и благодаря ей происходит расчёт максимального количества процессов.   
По-умолчанию  
vagrant@vagrant:~$ cat /sys/fs/cgroup/pids/user.slice/user-1000.slice/pids.max  
2446  
При превышении данного количества cgroups начинает блокировать создание процессов  

Для изменения числа процессов, которое можно создать в сессии, необходимо воспользоваться коммандой   

ulimit -u она позволит изменить ограничение (the maximum number of user processes)  














